{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import time\n",
    "import math\n",
    "import numpy as np\n",
    "import os\n",
    "from imutils import perspective\n",
    "import operator\n",
    "import imutils\n",
    "import copy\n",
    "import random\n",
    "from scipy.spatial import distance as dist\n",
    "import mrcnn.config\n",
    "import mrcnn.utils\n",
    "from mrcnn.model import MaskRCNN\n",
    "import os\n",
    "import random \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration that will be used by the Mask-RCNN library\n",
    "class MaskRCNNConfig(mrcnn.config.Config):\n",
    "    #NAME = \"coco_pretrained_model_config\"\n",
    "    NAME = \"nam,e\"\n",
    "    IMAGES_PER_GPU = 1\n",
    "    GPU_COUNT = 1\n",
    "    NUM_CLASSES = 1 + 1  \n",
    "    DETECTION_MIN_CONFIDENCE = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter a list of Mask R-CNN detection results to get only the detected picsf \n",
    "def get_pic_boxes(boxes, class_ids):\n",
    "    pic_boxes = []\n",
    "\n",
    "    for i, box in enumerate(boxes):\n",
    "        # If the detected object isn't an expected output, skip it\n",
    "        if class_ids[i] in [1]:\n",
    "            pic_boxes.append(box)\n",
    "\n",
    "    return np.array(pic_boxes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root ./\n",
      "model ./frame.h5\n"
     ]
    }
   ],
   "source": [
    "# Root directory of the project\n",
    "ROOT_DIR =\"./\"\n",
    "\n",
    "# Directory to save logs and trained model\n",
    "MODEL_DIR = os.path.join(ROOT_DIR, \"logs\")\n",
    "\n",
    "# Local path to trained weights file\n",
    "MODEL_PATH = os.path.join(ROOT_DIR, \"frame.h5\")\n",
    "\n",
    "# Create a Mask-RCNN model in inference mode\n",
    "model = MaskRCNN(mode=\"inference\", model_dir=MODEL_DIR, config=MaskRCNNConfig())\n",
    "\n",
    "print(\"root\",ROOT_DIR)\n",
    "print(\"model\",MODEL_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(MODEL_PATH, by_name=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Screen Shot 2020-09-13 at 12.40.16.png\n",
      "<class 'numpy.ndarray'> size: (600, 900, 3)\n",
      "going in model shape: (600, 900, 3)\n",
      "Processing 1 images\n",
      "image                    shape: (600, 900, 3)         min:    8.00000  max:  252.00000  uint8\n",
      "molded_images            shape: (1, 1024, 1024, 3)    min: -123.70000  max:  147.10000  float64\n",
      "image_metas              shape: (1, 14)               min:    0.00000  max: 1024.00000  float64\n",
      "anchors                  shape: (1, 261888, 4)        min:   -0.35390  max:    1.29134  float32\n",
      "total pics: 5\n"
     ]
    }
   ],
   "source": [
    "path = \".\\Frames_data\"\n",
    "files=os.listdir(path)\n",
    "d=random.choice(files)\n",
    "print(d)\n",
    "path = os.path.join(path,d)\n",
    "#img = cv2.imread(path,cv2.IMREAD_GRAYSCALE)\n",
    "img = cv2.imread(path,-1) #  -1 = unchanged\n",
    "cv2.imwrite(\".\\input_a.jpg\",img)\n",
    "img = cv2.resize(img, (900, 600))\n",
    "\n",
    "if d[-3:]==\"png\":\n",
    "    trans_mask = img[:,:,3] == 0\n",
    "    img[trans_mask] = [255, 255, 255, 255]\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGRA2BGR)\n",
    "\n",
    "cv2.imshow(\"Original Image\",img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "print(type(img),\"size:\",img.shape)\n",
    "print(\"going in model shape:\",img.shape)\n",
    "results = model.detect([img], verbose=1)\n",
    "\n",
    "\n",
    "r = results[0]\n",
    "pic_boxes = get_pic_boxes(r['rois'], r['class_ids'])\n",
    "print(\"total pics:\",len(pic_boxes))\n",
    "count=1\n",
    "for box in pic_boxes:\n",
    "    y1, x1, y2, x2 = box\n",
    "    b = x1,y1,x2,y2\n",
    "    #img = cv2.rectangle(img, (x1, y1), (x2, y2), (255,0 , 255),2)\n",
    "    crop_img = img[y1:y2, x1:x2]\n",
    "    cv2.imshow(\"Original Image\",crop_img)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "    cv2.imwrite(f\".\\output_a_{count}.jpg\",crop_img)\n",
    "    count=count+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
